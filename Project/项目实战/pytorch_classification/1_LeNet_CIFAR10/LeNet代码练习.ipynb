{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet代码练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （1）__LeNet__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 __LeNet5_model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 另一种写法\\nclass LeNet(nn.Module):\\n    def __init__(self):\\n        super().__init__()\\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5)\\n        self.max_pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\\n        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5)\\n        self.max_pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\\n        self.input_fc = nn.Linear(in_features=32 * 5 * 5, out_features=120)\\n        self.hidden_fc = nn.Linear(in_features=120, out_features=84)\\n        self.output_fc = nn.Linear(in_features=84, out_features=10)\\n\\n    def forward(self, x):\\n        x = F.relu(self.conv1(x))\\n        x = self.max_pool1(x)\\n        x = F.relu(self.conv2(x))\\n        x = self.max_pool2(x)\\n\\n        x = x.view(-1, 32 * 5 * 5)\\n        x = F.relu(self.input_fc(x))\\n        x = F.relu(self.hidden_fc(x))\\n        x = self.output_fc(x)\\n\\n        return x\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# 没有参数的层尽量使用torch.nn.functional函数,\n",
    "# 比如激活F.relu(input)、池化F.max_pool2d(input),\n",
    "# 但是只能用在前向传播函数中，因为需要传入被池化或激活的参数。\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Sequential接受OrderedDict,我们可以用它来命名传递给Sequential的每个模块,\n",
    "# 方便给模型的每一层命名。\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "# 这里的LeNet模型是针对CIFAR数据集（图像大小3X32X32），\n",
    "# 所以不用像LeNet论文那样为了使用mnist数据集（图像大小1X28X28）要先将图像填充到32X32。\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"conv1\", nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5)),\n",
    "                    (\"relu1\", nn.ReLU()),\n",
    "                    (\"max_pool1\", nn.MaxPool2d(kernel_size=2, stride=2)),\n",
    "                    (\n",
    "                        \"conv2\",\n",
    "                        nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5),\n",
    "                    ),\n",
    "                    (\"relu2\", nn.ReLU()),\n",
    "                    (\"max_pool2\", nn.MaxPool2d(kernel_size=2, stride=2)),\n",
    "                    # nn.Flatten()将某些连续的维度展平，然后才能正确输入全连接层。\n",
    "                    # 也可以在前向传播函数中使用x = x.view(-1, 32 * 5 * 5)将卷积后的数据\n",
    "                    # 变成能够输入全连接层的形状，32 * 5 * 5是全连接层中输入层的大小，\n",
    "                    # -1表示自适应。\n",
    "                    # 意思就是将每个卷积后的样本展开为一个列向量，\n",
    "                    # 这个列向量的长度是全连接层的输入层的节点数，如果不对应则无法前向传播。\n",
    "                    # 这里展开后尺寸是（1, 800）\n",
    "                    (\"flatten\", nn.Flatten()),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"input_fc\", nn.Linear(in_features=32 * 5 * 5, out_features=120)),\n",
    "                    (\"relu_fc1\", nn.ReLU()),\n",
    "                    (\"hidden_fc\", nn.Linear(in_features=120, out_features=84)),\n",
    "                    (\"relu_fc2\", nn.ReLU()),\n",
    "                    (\"output_fc\", nn.Linear(in_features=84, out_features=10)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        # 经过卷积进入全连接层需要展平才能正确输入,不然会出错。\n",
    "        # 如果在卷积层中使用了nn.Flatten()进行展平则不需要x.view()。\n",
    "        # x = x.view(-1, 32 * 5 * 5)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# 另一种写法\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5)\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5)\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.input_fc = nn.Linear(in_features=32 * 5 * 5, out_features=120)\n",
    "        self.hidden_fc = nn.Linear(in_features=120, out_features=84)\n",
    "        self.output_fc = nn.Linear(in_features=84, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.max_pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.max_pool2(x)\n",
    "\n",
    "        x = x.view(-1, 32 * 5 * 5)\n",
    "        x = F.relu(self.input_fc(x))\n",
    "        x = F.relu(self.hidden_fc(x))\n",
    "        x = self.output_fc(x)\n",
    "\n",
    "        return x\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0647, -0.0014,  0.0293, -0.0876,  0.0110, -0.0100,  0.1181, -0.0094,\n",
      "          0.0158, -0.0840],\n",
      "        [-0.0655,  0.0060,  0.0337, -0.0853,  0.0127, -0.0088,  0.1295, -0.0054,\n",
      "          0.0132, -0.0820]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lenet = LeNet()\n",
    "# print(lenet)\n",
    "import torch\n",
    "\n",
    "# 输入两个大小为（3, 32, 32）的张量，可看做两张图像。\n",
    "x = torch.rand([2, 3, 32, 32])\n",
    "y = lenet(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 __train__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 要运行需要将train_set和val_set的download改为True，或者自行加载已经下载的数据。\n",
    "\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=False, transform=transform\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=36, shuffle=True, num_workers=0\n",
    ")\n",
    "\n",
    "val_set = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=False,\n",
    "    transform=transform,\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_set, batch_size=5000, shuffle=False, num_workers=0\n",
    ")\n",
    "\n",
    "val_data_iter = iter(val_loader)\n",
    "val_image, val_label = next(val_data_iter)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lenet.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for step, data in enumerate(train_loader, start=0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = lenet(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if step % 500 == 499:  # 每500 mini-batches执行一次,因为下标从0开始所以这样写。\n",
    "            with torch.no_grad():\n",
    "                outputs = lenet(val_image)  # [batch, 10]\n",
    "                predict_y = torch.max(outputs, dim=1)[1]\n",
    "                accuracy = torch.eq(predict_y, val_label).sum().item() / val_label.size(\n",
    "                    0\n",
    "                )\n",
    "\n",
    "                print(\n",
    "                    \"[%d, %5d] train_loss: %.3f  test_accuracy: %.3f\"\n",
    "                    % (epoch + 1, step + 1, running_loss / 500, accuracy)\n",
    "                )\n",
    "                running_loss = 0.0\n",
    "\n",
    "print(\"Finished Training\")\n",
    "\n",
    "save_path = \"./Lenet.pth\"\n",
    "torch.save(lenet.state_dict(), save_path)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 __predict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "这张图片是： plane\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# 由于自己写的LeNet5_model的结构和model.py中的LeNet结构不同，\n",
    "# 而且文件夹中保存的模型权重文件Lenet.pth是由model.py中的LeNet训练得到，\n",
    "# 所以预测时要使用model.py中的LeNet进行模型初始化，才能正确加载权重文件Lenet.pth\n",
    "from model import LeNet as LeNet5\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "classes = (\n",
    "    \"plane\",\n",
    "    \"car\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    ")\n",
    "\n",
    "lenet_predict = LeNet5()\n",
    "lenet_predict.load_state_dict(torch.load(\"Lenet.pth\"))\n",
    "\n",
    "image = Image.open(\"./test_image/0_3.jpg\")\n",
    "image = transform(image)  # 图尺寸[C,H,W]\n",
    "image = torch.unsqueeze(image, dim=0)  # 图尺寸[N=1,C,H,W],增加批量大小维度N。\n",
    "\n",
    "# 预测时关闭梯度，禁止反向传播。\n",
    "with torch.no_grad():\n",
    "    output = lenet_predict(image)\n",
    "    # predict = torch.max(output, dim=1)[1].numpy()\n",
    "    # 直接得到输出最大值的索引indices，而不是每次根据输入的图片指定其索引[1],[2],[3]\n",
    "    predict = torch.max(output, dim=1).indices.numpy()\n",
    "\n",
    "print(torch.max(output, dim=1).indices.numpy())\n",
    "print(\"这张图片是：\", classes[int(predict)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
