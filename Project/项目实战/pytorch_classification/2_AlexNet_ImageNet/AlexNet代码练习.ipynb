{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet代码练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （1）**AlexNet_model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict  # 这个库方便给网络每一层添加名字。\n",
    "\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=1000, init_weights=False):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=3, out_channels=48, kernel_size=11, padding=2, stride=4\n",
    "            ),  # input[3, 224, 224]  output[48, 55, 55]\n",
    "            nn.ReLU(inplace=True),  # 参数表示是否会修改输入对象的值\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # output[48, 27, 27]\n",
    "            nn.Conv2d(\n",
    "                in_channels=48, out_channels=128, kernel_size=5, padding=2\n",
    "            ),  # output[128, 27, 27]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # output[128, 13, 13]\n",
    "            nn.Conv2d(\n",
    "                in_channels=128, out_channels=192, kernel_size=3, padding=1\n",
    "            ),  # output[192, 13, 13]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=192, out_channels=192, kernel_size=3, padding=1\n",
    "            ),  # output[192, 13, 13]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=192, out_channels=128, kernel_size=3, padding=1\n",
    "            ),  # output[128, 13, 13]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # output[128, 6, 6]\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),  # 神经元随机失活，避免过拟合的一种操作。\n",
    "            nn.Linear(in_features=128 * 6 * 6, out_features=2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=2048, out_features=2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=2048, out_features=num_classes),\n",
    "        )\n",
    "\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        # 维度从0开始，将1到最后一个维度展平以输入全连接层。\n",
    "        x = torch.flatten(x, start_dim=1, end_dim=-1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"初始化权重\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "net = AlexNet()\n",
    "x = torch.rand([1, 3, 224, 224])\n",
    "y = net(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （2）**train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练前先下载数据，正确设置训练、验证的数据路径。\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"使用{}进行训练\".format(device))\n",
    "\n",
    "data_transform = {\n",
    "    \"train_transform\": transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ]\n",
    "    ),\n",
    "    \"val_transform\": transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((224, 224)),  # cannot 224, must (224, 224)\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "data_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))  # get data root path\n",
    "image_path = os.path.join(data_root, \"data_set\", \"flower_data\")  # flower data set path\n",
    "assert os.path.exists(image_path), \"{} path does not exist.\".format(image_path)\n",
    "# datasets.ImageFolder()是加载自己的数据集，需要将数据分类放在不同的文件夹中，\n",
    "# 文件夹名就是数据类别名。\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    root=os.path.join(image_path, \"train\"), transform=data_transform[\"train_transform\"]\n",
    ")\n",
    "train_num = len(train_dataset)\n",
    "\n",
    "# 建立花类别的json文件\n",
    "flower_list = train_dataset.class_to_idx\n",
    "cla_dict = dict((val, key) for key, val in flower_list.items())\n",
    "# write dict into json file\n",
    "json_str = json.dumps(cla_dict, indent=4)\n",
    "with open(\"class_indices.json\", \"w\") as json_file:\n",
    "    json_file.write(json_str)\n",
    "\n",
    "# 确定用几个进程加载数据\n",
    "batch_size = 32\n",
    "nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n",
    "print(\"Using {} dataloader workers every process\".format(nw))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=nw\n",
    ")\n",
    "\n",
    "validate_dataset = datasets.ImageFolder(\n",
    "    root=os.path.join(image_path, \"val\"), transform=data_transform[\"val_transform\"]\n",
    ")\n",
    "val_num = len(validate_dataset)\n",
    "validate_loader = torch.utils.data.DataLoader(\n",
    "    validate_dataset, batch_size=4, shuffle=False, num_workers=nw\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"using {} images for training, {} images for validation.\".format(train_num, val_num)\n",
    ")\n",
    "\n",
    "alexnet = AlexNet(num_classes=5, init_weights=True)\n",
    "net.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0002)\n",
    "\n",
    "epochs = 10\n",
    "save_path = \"./AlexNet.pth\"\n",
    "best_acc = 0.0\n",
    "train_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # train\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    # 显示训练进度条\n",
    "    train_bar = tqdm(train_loader, file=sys.stdout)\n",
    "    for step, data in enumerate(train_bar):\n",
    "        images, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images.to(device))\n",
    "        loss = loss_function(outputs, labels.to(device))\n",
    "        loss.backward()\n",
    "        # 更新参数\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(\n",
    "            epoch + 1, epochs, loss\n",
    "        )\n",
    "\n",
    "    # validate\n",
    "    net.eval()\n",
    "    acc = 0.0  # accumulate accurate number / epoch\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(validate_loader, file=sys.stdout)\n",
    "        for val_data in val_bar:\n",
    "            val_images, val_labels = val_data\n",
    "            outputs = net(val_images.to(device))\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
    "\n",
    "    val_accurate = acc / val_num\n",
    "    print(\n",
    "        \"[epoch %d] train_loss: %.3f  val_accuracy: %.3f\"\n",
    "        % (epoch + 1, running_loss / train_steps, val_accurate)\n",
    "    )\n",
    "\n",
    "    if val_accurate > best_acc:\n",
    "        best_acc = val_accurate\n",
    "        torch.save(net.state_dict(), save_path)\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （3）**predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import AlexNet\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# load image\n",
    "img_path = \"../tulip.jpg\"\n",
    "assert os.path.exists(img_path), \"file: '{}' dose not exist.\".format(img_path)\n",
    "img = Image.open(img_path)\n",
    "\n",
    "plt.imshow(img)\n",
    "# [N, C, H, W]\n",
    "img = data_transform(img)\n",
    "# expand batch dimension\n",
    "img = torch.unsqueeze(img, dim=0)\n",
    "\n",
    "# read class_indict\n",
    "json_path = \"./class_indices.json\"\n",
    "assert os.path.exists(json_path), \"file: '{}' dose not exist.\".format(json_path)\n",
    "\n",
    "with open(json_path, \"r\") as f:\n",
    "    class_indict = json.load(f)\n",
    "\n",
    "# create model\n",
    "model = AlexNet(num_classes=5).to(device)\n",
    "\n",
    "# load model weights\n",
    "weights_path = \"./AlexNet.pth\"\n",
    "assert os.path.exists(weights_path), \"file: '{}' dose not exist.\".format(weights_path)\n",
    "model.load_state_dict(torch.load(weights_path))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # predict class\n",
    "    output = torch.squeeze(model(img.to(device))).cpu()\n",
    "    predict = torch.softmax(output, dim=0)\n",
    "    predict_cla = torch.argmax(predict).numpy()\n",
    "\n",
    "print_res = \"class: {}   prob: {:.3}\".format(\n",
    "    class_indict[str(predict_cla)], predict[predict_cla].numpy()\n",
    ")\n",
    "plt.title(print_res)\n",
    "for i in range(len(predict)):\n",
    "    print(\"class: {:10}   prob: {:.3}\".format(class_indict[str(i)], predict[i].numpy()))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
